{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Company Bankruptcy using Machine Learning\n",
    "By CS3244 Project Team 11  \n",
    "Cao Han  |  Chin Sek Yi  |  Lim Kai Sin  |  Luo Xinming  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Chapter 1: Project Overview](#chapter1)\n",
    "    * [1.1 Project Motivation](#section1_1)\n",
    "    * [1.2 Dataset Description](#section1_2)\n",
    "    * [1.3 Methodologies](#section1_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1: Project Overview <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Project Motivation <a id=\"section1_1\"></a>\n",
    "In today's dynamic business landscape, exemplified by recent events such as the bankruptcy of Silicon Valley Bank, the ability to anticipate and mitigate financial risks is crucial for sustainable growth and stability. This project aims to develop a robust predictive model of company bankruptcy, leveraging advanced machine learning algorithms and financial data analysis techniques, so as to equip stakeholders with nuanced insights to confidently traverse the unpredictable landscape of financial risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Dataset Description <a id=\"section1_2\"></a>\n",
    "The dataset used in this project is about bankruptcy prediction of Polish companies. The dataset contains financial rates from one year and corresponding class label that indicates bankruptcy status 3 years after that year. The data contains 10503 instances (financial statements), with 495 representing bankrupted companies and 10008 still operating at the end of the 3-year forecasting period.\n",
    "\n",
    "The data was collected from [Emerging Markets Information Service](http://www.securities.com), which is a database containing information on emerging markets around the world. The bankrupt companies were analyzed in the period 2000-2012, while the still operating companies were evaluated from 2007 to 2013.  \n",
    "\n",
    "Source: [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/dataset/365/polish+companies+bankruptcy+data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Methodologies <a id=\"section1_3\"></a>\n",
    "This project attempts to explore the effectiveness of a diverse array of machine learning algorithms, including logistic regression, svm, k nearest neighbors and decision trees in predicting company brankruptcy, using logistic regression (linear model) as the benchmark for comparison. The project leverages ensemble methods including bagging, boosting and random forests to amplify our model's predictive capabilities, while enriching our understanding of machine learning techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 Library Loading <a id=\"section1_3_1\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "from scipy.io import arff\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 Dataset Collection <a id=\"section1_3_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_url = \"https://archive.ics.uci.edu/static/public/365/polish+companies+bankruptcy+data.zip\"\n",
    "response = requests.get(download_url)\n",
    "zip_file_path = \"downloaded_file.zip\"\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open(zip_file_path, \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "else:\n",
    "    print(\"Failed to download the file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data Exploration (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Data pre-processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Data Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Evaluation Metrics\n",
    "\n",
    "Our primary task is to predict bankruptcy (a classification problem). Below are the key classification metrics that we will use to evaluate our model performance:\n",
    "\n",
    "### 4.1.1 Accuracy\n",
    "Accuracy provides a ratio of correctly predicted observations to the total observations. It is especially useful when the classes are balanced with SMOTE.\n",
    "\n",
    "**Formula**:\n",
    "$$\\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Predictions}}$$\n",
    "\n",
    "### 4.1.2 Confusion Matrix and Related Terms\n",
    "The confusion matrix is a table layout that allows visualization of the performance of the algorithm, where each number in the matrix represents:\n",
    "- **TP (True Positives)**: Correctly predicted positive observations.\n",
    "- **TN (True Negatives)**: Correctly predicted negative observations.\n",
    "- **FP (False Positives)**: Incorrectly predicted as positive.\n",
    "- **FN (False Negatives)**: Incorrectly predicted as negative.\n",
    "\n",
    "### 4.1.3 Precision, Recall, and F1-Score\n",
    "These metrics offer a deeper understanding of the model's performance by taking into account data imbalances, thereby providing a more nuanced view of the accuracy across different class labels.\n",
    "\n",
    "- **Precision**:\n",
    "$$ \\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}} $$\n",
    "Precision measures the accuracy of positive predictions.\n",
    "\n",
    "- **Recall** (or Sensitivity or TPR):\n",
    "$$ \\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}} $$\n",
    "Recall measures the ability of a model to find all the relevant cases (all positive samples).\n",
    "\n",
    "- **F1-Score**:\n",
    "$$ \\text{F1-Score} = 2 \\times \\left( \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} \\right) $$\n",
    "The F1-Score is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account. A high F1-score shows a model can classify the positive class correctly, while not misclassifying many negative classes as positive.\n",
    "\n",
    "#### Macro Average vs Micro Average\n",
    "\n",
    "- **Macro Average**: Macro average calculates the metric independently for each class and then takes the average (hence treating all classes equally). It is useful equal weight is given to the performance of each class, regardless of its frequency.\n",
    "\n",
    "- **Micro Average**: Micro average aggregates the contributions of all classes to compute the average metric. In other words, Micro Average will compute the overall total TP, FP, and FN across all classes, and then use these totals to calculate the performance scores. It is useful when metrics are weighted by class size, which is ideal for imbalanced data as it reflects the contribution of each class proportionally to its size.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Machine Learning Models \n",
    "\n",
    "### Scikit-learn (sklearn)\n",
    "- **KNeighborsClassifier**: This model implements the k-nearest neighbors voting algorithm.\n",
    "- **LogisticRegression**: A model that applies logistic regression for binary classification tasks.\n",
    "- **SVC**: Support Vector Machine classifier known for its effectiveness in high-dimensional spaces.\n",
    "- **DecisionTreeClassifier**: A model that uses a decision tree for classification, useful for interpretability.\n",
    "- **GradientBoostingClassifier**: An ensemble model that builds on weak prediction models to create a strong classifier.\n",
    "- **RandomForestClassifier**: A meta estimator that fits a number of decision tree classifiers to various sub-samples of the dataset and uses averaging to improve predictive accuracy and control overfitting.\n",
    "\n",
    "### Imbalanced-learn (imblearn)\n",
    "Dealing with imbalanced data:\n",
    "\n",
    "- **BalancedRandomForestClassifier**: A variation of the RandomForest that handles imbalances by adjusting weights inversely proportional to class frequencies in the input data.\n",
    "\n",
    "### XGBoost (xgboost)\n",
    "\n",
    "- **XGBoost**: An implementation of gradient boosted decision trees designed for speed and performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Our training approach\n",
    "\n",
    "### 4.2.1 Simple logistic regression\n",
    "We begin our modeling with a simple logistic regression to establish a baseline for benchmark performance.\n",
    "This approach provides an initial overview of how well simple models can predict outcomes based on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Numerical results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
