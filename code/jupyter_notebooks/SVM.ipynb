{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.io import arff\n",
    "import data_processing as dp\n",
    "#import python_scripts.data_processing as dp\n",
    "import warnings\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    precision_score,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "data = arff.loadarff(\"../../data/3year.arff\")\n",
    "df = pd.DataFrame(data[0])\n",
    "df_origin = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_model(*args):\n",
    "    X_train = args[0]\n",
    "    X_test = args[1]\n",
    "    y_train = args[2]\n",
    "    y_test = args[3]\n",
    "\n",
    "    # Reset indices to ensure alignment\n",
    "    X_train.reset_index(drop=True, inplace=True)\n",
    "    y_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Training the SVM model\n",
    "    svm_model = SVC(\n",
    "        kernel=\"linear\"\n",
    "    )  # You can choose different kernels based on your data\n",
    "    svm_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the testing set\n",
    "    y_pred_train = svm_model.predict(X_train)\n",
    "    y_pred_test = svm_model.predict(X_test)\n",
    "\n",
    "    # Evaluating the model\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    precision_score_ = precision_score(y_test, y_pred_test)\n",
    "    recall_score_ = recall_score(y_test, y_pred_test)\n",
    "    f1_score_ = f1_score(y_test, y_pred_test)\n",
    "\n",
    "    print(classification_report(y_test, y_pred_test))\n",
    "    print(f\"precision_score: {precision_score_}\")\n",
    "    print(f\"recall_score: {recall_score_}\")\n",
    "    print(f\"train_accuracy: {train_accuracy}\")\n",
    "    print(f\"test_accuracy: {test_accuracy}\")\n",
    "    print(f\"f1score: {f1_score_}\")\n",
    "\n",
    "    return train_accuracy, test_accuracy, y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_return_model(*args):\n",
    "    X_train = args[0]\n",
    "    X_test = args[1]\n",
    "    y_train = args[2]\n",
    "    y_test = args[3]\n",
    "\n",
    "    # Reset indices to ensure alignment\n",
    "    X_train.reset_index(drop=True, inplace=True)\n",
    "    y_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Training the SVM model\n",
    "    svm_model = SVC(\n",
    "        kernel=\"linear\"\n",
    "    )  # You can choose different kernels based on your data\n",
    "    svm_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the testing set\n",
    "    y_pred_train = svm_model.predict(X_train)\n",
    "    y_pred_test = svm_model.predict(X_test)\n",
    "\n",
    "    # Evaluating the model\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    precision_score_ = precision_score(y_test, y_pred_test)\n",
    "    recall_score_ = recall_score(y_test, y_pred_test)\n",
    "    f1_score_ = f1_score(y_test, y_pred_test)\n",
    "\n",
    "    print(classification_report(y_test, y_pred_test))\n",
    "    print(f\"precision_score: {precision_score_}\")\n",
    "    print(f\"recall_score: {recall_score_}\")\n",
    "    print(f\"train_accuracy: {train_accuracy}\")\n",
    "    print(f\"test_accuracy: {test_accuracy}\")\n",
    "    print(f\"f1score: {f1_score_}\")\n",
    "\n",
    "    return svm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (13978, 30)\n"
     ]
    }
   ],
   "source": [
    "train_test_dataset = dp.pre_process(df)  # with SMOTE\n",
    "print(f\"X_train.shape: {train_test_dataset[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Do:\n",
    "- check linear separability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.58      0.72      3017\n",
      "           1       0.05      0.47      0.09       134\n",
      "\n",
      "    accuracy                           0.57      3151\n",
      "   macro avg       0.50      0.52      0.40      3151\n",
      "weighted avg       0.92      0.57      0.69      3151\n",
      "\n",
      "precision_score: 0.04708520179372197\n",
      "recall_score: 0.4701492537313433\n",
      "train_accuracy: 0.537201316354271\n",
      "test_accuracy: 0.5728340209457315\n",
      "f1score: 0.08559782608695651\n",
      "0.537201316354271\n",
      "0.5728340209457315\n"
     ]
    }
   ],
   "source": [
    "train_accuracy, test_accuracy, y_pred_test = SVM_model(*train_test_dataset)\n",
    "print(train_accuracy)\n",
    "print(test_accuracy)\n",
    "\n",
    "# kernel = rbf , [train, test] = [0.5304764630133066, 0.5147572199301809]\n",
    "# kernel = linear, [train, test] = [0.537201316354271, 0.5728340209457315]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_train_test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_best_k_features_from_ANOVA\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mSVM_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrain_test_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# bc i added y_pred_test\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(best_train_test_dataset[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Best k for train_accuracy: 23\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Best k for test_accuracy: 25\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/CS3244-Bankruptcy-Prediction/code/jupyter_notebooks/data_processing.py:220\u001b[0m, in \u001b[0;36mfind_best_k_features_from_ANOVA\u001b[0;34m(model, *args)\u001b[0m\n\u001b[1;32m    217\u001b[0m train_test_dataset \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, original_n_features \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 220\u001b[0m     train_test_dataset_after_ANOVA \u001b[38;5;241m=\u001b[39m \u001b[43mget_df_with_top_k_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     train_accuracy, test_accuracy \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39mtrain_test_dataset_after_ANOVA)\n\u001b[1;32m    222\u001b[0m     train_test_dataset[k] \u001b[38;5;241m=\u001b[39m train_test_dataset_after_ANOVA\n",
      "File \u001b[0;32m~/Downloads/CS3244-Bankruptcy-Prediction/code/jupyter_notebooks/data_processing.py:182\u001b[0m, in \u001b[0;36mget_df_with_top_k_features\u001b[0;34m(k_features, *args)\u001b[0m\n\u001b[1;32m    180\u001b[0m X_train \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    181\u001b[0m X_test \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 182\u001b[0m y_train \u001b[38;5;241m=\u001b[39m \u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    183\u001b[0m y_test \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# define feature selection\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "best_train_test_dataset = dp.find_best_k_features_from_ANOVA(\n",
    "    SVM_model, *train_test_dataset[:2]  # bc i added y_pred_test\n",
    ")\n",
    "print(len(best_train_test_dataset[0].columns))\n",
    "# Best k for train_accuracy: 23\n",
    "# Best k for test_accuracy: 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'f1_score' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mSVM_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbest_train_test_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [22], line 26\u001b[0m, in \u001b[0;36mSVM_model\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     24\u001b[0m precision_score_ \u001b[38;5;241m=\u001b[39m precision_score(y_test, y_pred_test)\n\u001b[1;32m     25\u001b[0m recall_score_ \u001b[38;5;241m=\u001b[39m recall_score(y_test, y_pred_test)\n\u001b[0;32m---> 26\u001b[0m f1_score \u001b[38;5;241m=\u001b[39m \u001b[43mf1_score\u001b[49m(y_test, y_pred_test)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred_test)) \n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision_score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision_score_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'f1_score' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "SVM_model(*best_train_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = best_train_test_dataset\n",
    "conf_matrix = confusion_matrix(y_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV\n",
    "https://www.geeksforgeeks.org/svm-hyperparameter-tuning-using-gridsearchcv-ml/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.519 total time=  11.1s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.523 total time=  10.8s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.533 total time=  11.0s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.524 total time=  11.4s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.517 total time=  11.9s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.525 total time=  11.5s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.523 total time=  11.7s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.522 total time=  11.4s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.500 total time=  11.3s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.512 total time=  11.1s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.525 total time=  12.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.526 total time=  11.6s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.525 total time=  11.2s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.500 total time=  11.5s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.500 total time=  11.6s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.527 total time=  11.1s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.525 total time=  11.4s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.528 total time=  11.4s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.500 total time=  11.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.500 total time=  10.7s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.526 total time=  11.7s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.525 total time=  12.3s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.528 total time=  11.9s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.500 total time=  14.2s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.500 total time=  10.6s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.560 total time=  10.7s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.553 total time=  12.4s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.558 total time=  10.8s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.558 total time=  10.4s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.552 total time=  11.6s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.524 total time=  11.5s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.530 total time=  11.5s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.539 total time=  15.8s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.529 total time=  11.9s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.521 total time=  13.5s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.525 total time=  14.2s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.526 total time=  13.2s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.525 total time=  11.4s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.501 total time=  11.3s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.504 total time=  12.0s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.527 total time=  10.9s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.525 total time=  10.5s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.528 total time=  10.9s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.500 total time=  12.3s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.500 total time=  10.6s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.526 total time=  10.4s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.525 total time=  10.6s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.528 total time=  11.0s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.500 total time=  11.0s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.500 total time=  10.8s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.588 total time=  11.0s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.601 total time=  10.2s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.598 total time=  10.3s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.598 total time=  11.1s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.594 total time=  11.5s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.525 total time=  11.1s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.537 total time=  10.4s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.544 total time=  10.6s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.532 total time=  10.4s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.532 total time=  10.8s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.526 total time=  10.8s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.531 total time=  12.5s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.538 total time=  11.0s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.531 total time=  11.5s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.522 total time=  12.7s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.527 total time=  12.0s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.525 total time=  10.7s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.528 total time=  10.6s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.501 total time=  10.8s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.505 total time=  10.6s\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.526 total time=  11.4s\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.525 total time=  10.6s\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.528 total time=  10.4s\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.500 total time=  10.5s\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.500 total time=  10.9s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.642 total time=  10.7s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.649 total time=   9.9s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.657 total time=   9.9s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.656 total time=  10.2s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.653 total time=  10.7s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.598 total time=  10.5s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.611 total time=  10.5s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.602 total time=  11.4s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.604 total time=  10.9s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.597 total time=  10.6s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.533 total time=  11.1s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.542 total time=  11.6s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.546 total time=  11.4s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.536 total time=  10.8s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.533 total time=  11.4s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.526 total time=  10.8s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.530 total time=  12.0s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.538 total time=  11.4s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.532 total time=  10.9s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.522 total time=  10.7s\n",
      "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.526 total time=  10.6s\n",
      "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.525 total time=  12.2s\n",
      "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.528 total time=  15.8s\n",
      "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.501 total time=  11.1s\n",
      "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.505 total time=  11.6s\n",
      "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.690 total time=  11.0s\n",
      "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.686 total time=  10.6s\n",
      "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.707 total time=  10.8s\n",
      "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.692 total time=  11.3s\n",
      "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.701 total time=  11.0s\n",
      "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.634 total time=  10.8s\n",
      "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.645 total time=  10.7s\n",
      "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.655 total time=  11.2s\n",
      "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.648 total time=  12.2s\n",
      "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.647 total time=  12.7s\n",
      "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.607 total time=  10.9s\n",
      "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.613 total time=  10.2s\n",
      "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.613 total time=  11.9s\n",
      "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.620 total time=  11.2s\n",
      "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.612 total time=  11.3s\n",
      "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.535 total time=  10.7s\n",
      "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.541 total time=  10.6s\n",
      "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.546 total time=  11.4s\n",
      "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.536 total time=  11.6s\n",
      "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.534 total time=  11.0s\n",
      "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.525 total time=  11.4s\n",
      "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.530 total time=  11.8s\n",
      "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.538 total time=  12.1s\n",
      "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.532 total time=  12.0s\n",
      "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.522 total time=  11.5s\n",
      "{'C': 1000, 'gamma': 1, 'kernel': 'rbf'}\n",
      "SVC(C=1000, gamma=1)\n"
     ]
    }
   ],
   "source": [
    "# defining parameter range\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"C\": [0.1, 1, 10, 100, 1000],\n",
    "    \"gamma\": [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "    \"kernel\": [\"rbf\"],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=3)\n",
    "\n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# print best parameter after tuning\n",
    "print(grid.best_params_)\n",
    "\n",
    "\n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.58      0.72      3017\n",
      "           1       0.05      0.47      0.09       134\n",
      "\n",
      "    accuracy                           0.57      3151\n",
      "   macro avg       0.50      0.52      0.40      3151\n",
      "weighted avg       0.92      0.57      0.69      3151\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.53      0.69      3017\n",
      "           1       0.07      0.77      0.13       134\n",
      "\n",
      "    accuracy                           0.54      3151\n",
      "   macro avg       0.52      0.65      0.41      3151\n",
      "weighted avg       0.94      0.54      0.67      3151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_predictions = grid.predict(X_test)\n",
    "\n",
    "# print classification report\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "# print classification report\n",
    "print(classification_report(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.58      0.72      3017\n",
      "           1       0.05      0.47      0.09       134\n",
      "\n",
      "    accuracy                           0.57      3151\n",
      "   macro avg       0.50      0.52      0.40      3151\n",
      "weighted avg       0.92      0.57      0.69      3151\n",
      "\n",
      "precision_score: 0.04715568862275449\n",
      "recall_score: 0.4701492537313433\n",
      "train_accuracy: 0.5372728573472599\n",
      "test_accuracy: 0.5734687400825135\n",
      "f1score: 0.0857142857142857\n"
     ]
    }
   ],
   "source": [
    "clf = SVM_return_model(*best_train_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:158\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(slice(None, None, None), 0)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [50], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m intercept \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Plot data points\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, X[:, \u001b[38;5;241m1\u001b[39m], c\u001b[38;5;241m=\u001b[39my, cmap\u001b[38;5;241m=\u001b[39mplt\u001b[38;5;241m.\u001b[39mcm\u001b[38;5;241m.\u001b[39mPaired, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Plot support vectors\u001b[39;00m\n\u001b[1;32m     15\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(support_vectors[:, \u001b[38;5;241m0\u001b[39m], support_vectors[:, \u001b[38;5;241m1\u001b[39m], s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, facecolors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m, edgecolors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3896\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3898\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_indexing_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:5974\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5970\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   5971\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[1;32m   5972\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[1;32m   5973\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[0;32m-> 5974\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: (slice(None, None, None), 0)"
     ]
    }
   ],
   "source": [
    "\"\"\"from sklearn.svm import SVC\n",
    "\n",
    "X = X_train\n",
    "y = y_train\n",
    "\n",
    "# Get support vectors and coefficients\n",
    "support_vectors = clf.support_vectors_\n",
    "coef = clf.coef_[0]\n",
    "intercept = clf.intercept_\n",
    "\n",
    "# Plot data points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired, marker=\"o\")\n",
    "\n",
    "# Plot support vectors\n",
    "plt.scatter(\n",
    "    support_vectors[:, 0],\n",
    "    support_vectors[:, 1],\n",
    "    s=100,\n",
    "    facecolors=\"none\",\n",
    "    edgecolors=\"k\",\n",
    ")\n",
    "\n",
    "# Plot decision boundary\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contour(\n",
    "    xx, yy, Z, colors=\"k\", levels=[-1, 0, 1], alpha=0.5, linestyles=[\"--\", \"-\", \"--\"]\n",
    ")\n",
    "\n",
    "# Plot hyperplane\n",
    "plt.plot(xx, (-coef[0] * xx - intercept) / coef[1], \"k--\")\n",
    "\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.title(\"SVM Decision Boundary\")\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
