{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "81606536-66f4-4679-89d3-87a370cb5300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.io import arff\n",
    "import python_scripts.data_processing as dp\n",
    "\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5d79fa43-ea94-4b64-8bc8-bb1720005beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata = arff.loadarff(\"../data/3year.arff\")\\ndf = pd.DataFrame(data[0])\\nX_train, X_test, y_train, y_test = dp.get_train_test(df)\\n\\ny_test = pd.Series(y_test[0])\\ny_train = pd.Series(y_train[0])\\n'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "data = arff.loadarff(\"../data/3year.arff\")\n",
    "df = pd.DataFrame(data[0])\n",
    "X_train, X_test, y_train, y_test = dp.get_train_test(df)\n",
    "\n",
    "y_test = pd.Series(y_test[0])\n",
    "y_train = pd.Series(y_train[0])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "28eb8e28-4bac-4c3d-846d-ca2e0bb31a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = arff.loadarff(\"../data/3year.arff\")\n",
    "df = pd.DataFrame(data[0])\n",
    "y = df.iloc[:, -1]\n",
    "df = df.iloc[:, :64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8219e29f-8be4-4672-8bc7-85a720f9d3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_discrete(col):\n",
    "    n = len(col)\n",
    "    new_col = [0] * n\n",
    "    for i in range(n):\n",
    "        if col[i] == b\"0\":\n",
    "            new_col[i] = 0\n",
    "        else:\n",
    "            new_col[i] = 1\n",
    "    return pd.Series(new_col)\n",
    "\n",
    "\n",
    "y = as_discrete(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "3bd98dc6-a32d-4c5e-9d1c-3cd72b1dd468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def med_impute(df, y):\n",
    "    # remove columns with more than 40% values being null\n",
    "    thd1 = df.shape[0] * 0.4\n",
    "    cols = df.columns[df.isnull().sum() < thd1]\n",
    "    df = df[cols]\n",
    "\n",
    "    # remove rows with more than 50% values being null\n",
    "    thd2 = df.shape[1] * 0.5\n",
    "    y = y[df.isnull().sum(axis=1) <= thd2]\n",
    "    df = df[df.isnull().sum(axis=1) <= thd2]\n",
    "\n",
    "    # median imputation for null values\n",
    "    for column in df.columns:\n",
    "        df[column] = df[column].fillna(df[column].median())\n",
    "\n",
    "    return df, y\n",
    "\n",
    "\n",
    "df, y = med_impute(df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f9a29e72-4753-42de-88ee-b749e82521a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df, y, test_size=0.2, random_state=1000\n",
    ")\n",
    "sum(y_test == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1d95cf9d-5214-4765-8523-1a5b134fdc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9509757258448358\n"
     ]
    }
   ],
   "source": [
    "# Initialize KNN classifier with k=5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4a13ce61-369f-4dba-a859-d0360bcf6e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def normalise(df):\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "\n",
    "    return X_scaled\n",
    "\n",
    "\n",
    "df1 = normalise(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a57a22b1-625d-49d8-8e8d-37485887ffe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of           Attr5     Attr9    Attr13    Attr15    Attr21    Attr24    Attr26  \\\n",
       "0      0.945548  0.003252  0.112756  0.184936  0.000070  0.255539  0.024190   \n",
       "1      0.945550  0.003799  0.112753  0.184955  0.000207  0.253054  0.024176   \n",
       "2      0.945557  0.002998  0.112736  0.185056  0.000060  0.253371  0.024149   \n",
       "3      0.945549  0.003056  0.112737  0.185152  0.000058  0.254762  0.024143   \n",
       "4      0.945545  0.003445  0.112764  0.184937  0.000077  0.252395  0.024189   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "10496  0.945548  0.003004  0.112734  0.185118  0.000070  0.252407  0.024145   \n",
       "10497  0.945551  0.002916  0.112734  0.185437  0.000061  0.252253  0.024133   \n",
       "10498  0.945539  0.003122  0.112709  0.184704  0.000069  0.251848  0.024111   \n",
       "10499  0.945549  0.003004  0.112733  0.185430  0.000062  0.252427  0.024137   \n",
       "10500  0.945546  0.004507  0.112733  0.186036  0.000079  0.252476  0.024133   \n",
       "\n",
       "         Attr27    Attr29    Attr32  ...    Attr54    Attr55    Attr56  \\\n",
       "0      0.065267  0.631946  0.001406  ...  0.101939  0.212654  0.951045   \n",
       "1      0.065282  0.444732  0.001407  ...  0.102077  0.182669  0.951023   \n",
       "2      0.065267  0.499130  0.001401  ...  0.102129  0.186799  0.951019   \n",
       "3      0.065267  0.462851  0.001406  ...  0.102037  0.183063  0.951026   \n",
       "4      0.065282  0.497256  0.001409  ...  0.102101  0.185172  0.951047   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "10496  0.065267  0.465427  0.001397  ...  0.101878  0.180804  0.951020   \n",
       "10497  0.065267  0.533223  0.001395  ...  0.101946  0.185114  0.951009   \n",
       "10498  0.065266  0.446075  0.001428  ...  0.101848  0.180825  0.951042   \n",
       "10499  0.065267  0.437958  0.001406  ...  0.102088  0.182500  0.951020   \n",
       "10500  0.065267  0.349347  0.001412  ...  0.101935  0.181851  0.951022   \n",
       "\n",
       "         Attr58    Attr59        Attr60    Attr61    Attr62    Attr63  \\\n",
       "0      0.010893  0.022090  2.654090e-06  0.002875  0.685215  0.002193   \n",
       "1      0.010897  0.022090  1.636031e-06  0.002390  0.685221  0.001809   \n",
       "2      0.010902  0.022090  1.850773e-06  0.002319  0.685210  0.002851   \n",
       "3      0.010899  0.022109  1.155292e-06  0.002601  0.685220  0.001871   \n",
       "4      0.010893  0.022100  7.079395e-07  0.003052  0.685220  0.001839   \n",
       "...         ...       ...           ...       ...       ...       ...   \n",
       "10496  0.010901  0.022132  1.042074e-05  0.010217  0.685203  0.004380   \n",
       "10497  0.010905  0.022238  3.959620e-06  0.003546  0.685200  0.005643   \n",
       "10498  0.010894  0.022195  1.714032e-06  0.003638  0.685253  0.000871   \n",
       "10499  0.010901  0.022090  1.630375e-06  0.002444  0.685219  0.001882   \n",
       "10500  0.010901  0.022398  2.063057e-06  0.002365  0.685232  0.001310   \n",
       "\n",
       "         Attr64  \n",
       "0      0.000188  \n",
       "1      0.000277  \n",
       "2      0.000207  \n",
       "3      0.000162  \n",
       "4      0.000216  \n",
       "...         ...  \n",
       "10496  0.000245  \n",
       "10497  0.000090  \n",
       "10498  0.000073  \n",
       "10499  0.000363  \n",
       "10500  0.000569  \n",
       "\n",
       "[10501 rows x 30 columns]>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def drop_high_corr(df, threshold=0.7):\n",
    "\n",
    "    correlation_matrix = df.corr()\n",
    "    high_cor = []\n",
    "    dropped_features = []\n",
    "\n",
    "    # Iterate through the correlation matrix to find highly correlated pairs\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(correlation_matrix.iloc[i, j]) > threshold:\n",
    "                if correlation_matrix.columns[j] != correlation_matrix.columns[i]:\n",
    "                    high_cor.append(\n",
    "                        [\n",
    "                            correlation_matrix.columns[i],\n",
    "                            correlation_matrix.columns[j],\n",
    "                            correlation_matrix.iloc[i, j],\n",
    "                        ]\n",
    "                    )\n",
    "\n",
    "    # Iterate through the list of highly correlated pairs\n",
    "    for pair in high_cor:\n",
    "        feature1, feature2, correlation = pair\n",
    "\n",
    "        # Check if either of the features in the pair has already been dropped\n",
    "        if feature1 not in dropped_features and feature2 not in dropped_features:\n",
    "            # Check if the feature exists in the DataFrame before attempting to drop it\n",
    "            if feature2 in df.columns:\n",
    "                # Drop one of the correlated features from the dataset\n",
    "                # Here, we arbitrarily choose to drop the second feature in the pair\n",
    "                df.drop(feature2, axis=1, inplace=True)\n",
    "                dropped_features.append(feature2)\n",
    "            else:\n",
    "                print(f\"Feature '{feature2}' not found in the DataFrame.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df1 = drop_high_corr(df1, threshold=0.7)\n",
    "df1.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "aaf5df7e-44ea-4099-8638-b9b9c84bdc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9576392194193242\n"
     ]
    }
   ],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(\n",
    "    df1, y, test_size=0.2, random_state=148\n",
    ")\n",
    "\n",
    "# Initialize KNN classifier with k=5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model\n",
    "knn.fit(X_train1, y_train1)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred1 = knn.predict(X_test1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test1, y_pred1)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ab13fd-0c85-4914-8866-e717ae3259d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
