{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we shall perform feature selection to reduce the dimensionality of our data, and to retain the most important features.\n",
    "\n",
    "## Table of Contents\n",
    "1. [ANOVA test for Feature selection](#chapter1)\n",
    "2. [Filter Method for Feature Selection](#chapter2)\n",
    "3. [Wrapper Method for Feature Selection](#chapter3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10501, 64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Acess dataframe from EDA step\n",
    "df_to_share = pd.read_pickle(\"df_to_share.pkl\")\n",
    "df_to_share.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ANOVA test for feature selection\n",
    "We will also perform feature selection for our dataset, because irrelavant features can:\n",
    "- **Increase Model Complexity**: Unnecessary features can lead to overfitting, where the model performs well on training data but poorly on unseen data.\n",
    "- **Reduce Model Interpretability**: A large number of features makes it difficult to understand how the model arrives at its predictions.\n",
    "- **Slow Down Training Time**: Training models with irrelevant features takes longer and consumes more computational resources.\n",
    "\n",
    "One method of feature selection is ANOVA test, defined in: `get_df_with_top_k_features` and `find_best_k_features_from_ANOVA`\n",
    "\n",
    "**ANOVA (Analysis of Variance)** is a statistical test used in feature selection to identify features that have a significant influence on the target variable. Here's how it helps select the best k features (where k is a chosen number):\n",
    "\n",
    "- Focuses on Variance: ANOVA analyses the variation in a feature's values. It compares the variation between groups (bankrupt vs. non-bankrupt) to the variation within each group.\n",
    "- Low p-value indicates Impact: Features with a low p-value (from the F-statistic) suggest a strong statistical difference in the feature's values between bankrupt and non-bankrupt companies. This implies the feature likely has a real impact on predicting bankruptcy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ANOVA_test_graph(train_acc_dict, test_acc_dict):\n",
    "    # Extract keys and values from train_acc_dict and test_acc_dict\n",
    "    train_k_values, train_accuracy_values = zip(*train_acc_dict.items())\n",
    "    test_k_values, test_accuracy_values = zip(*test_acc_dict.items())\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    # Plot train accuracy\n",
    "    plt.plot(\n",
    "        train_k_values, train_accuracy_values, label=\"Train Accuracy\", color=\"blue\"\n",
    "    )\n",
    "    # Plot test accuracy\n",
    "    plt.plot(test_k_values, test_accuracy_values, label=\"Test Accuracy\", color=\"green\")\n",
    "\n",
    "    # Find k values corresponding to maximum accuracies\n",
    "    best_train_k = max(train_acc_dict, key=train_acc_dict.get)\n",
    "    best_test_k = max(test_acc_dict, key=test_acc_dict.get)\n",
    "    best_train_accuracy = train_acc_dict[best_train_k]\n",
    "    best_test_accuracy = test_acc_dict[best_test_k]\n",
    "\n",
    "    # Annotate the point corresponding to the peak train accuracy\n",
    "    plt.annotate(\n",
    "        f\"Max Train Accuracy\\nk={best_train_k}, Acc={best_train_accuracy:.2f}\",\n",
    "        xy=(best_train_k, best_train_accuracy),\n",
    "        xytext=(-30, 20),\n",
    "        textcoords=\"offset points\",\n",
    "        arrowprops=dict(arrowstyle=\"->\", color=\"blue\"),\n",
    "    )\n",
    "\n",
    "    # Annotate the point corresponding to the peak test accuracy\n",
    "    plt.annotate(\n",
    "        f\"Max Test Accuracy\\nk={best_test_k}, Acc={best_test_accuracy:.2f}\",\n",
    "        xy=(best_test_k, best_test_accuracy),\n",
    "        xytext=(30, -30),\n",
    "        textcoords=\"offset points\",\n",
    "        arrowprops=dict(arrowstyle=\"->\", color=\"green\"),\n",
    "    )\n",
    "\n",
    "    # Label axes and add title\n",
    "    plt.xlabel(\"Number of Features (k)\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Accuracy vs. Number of Features from ANOVA test\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "## Note: *args follow the convention X_train, X_test, y_train, y_test\n",
    "def get_df_with_top_k_features(k_features, *args):  # after pre_process(df)\n",
    "    X_train = args[0]\n",
    "    X_test = args[1]\n",
    "    y_train = args[2]\n",
    "    y_test = args[3]\n",
    "\n",
    "    # define feature selection\n",
    "    fs = SelectKBest(score_func=f_classif, k=k_features)\n",
    "\n",
    "    # apply feature selection\n",
    "    fs.fit_transform(X_train, y_train)\n",
    "\n",
    "    # Take the features with the highest F-scores\n",
    "    fs_scores_array = np.array(fs.scores_)\n",
    "\n",
    "    # Get the indices that would sort the array in descending order\n",
    "    sorted_indices_desc = np.argsort(fs_scores_array)[::-1]\n",
    "\n",
    "    # Take the top k indices\n",
    "    top_indices = sorted_indices_desc[:k_features]\n",
    "\n",
    "    selected_columns_X_train = X_train.iloc[:, top_indices]\n",
    "    selected_columns_X_test = X_test.iloc[:, top_indices]\n",
    "\n",
    "    return selected_columns_X_train, selected_columns_X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def find_best_k_features_from_ANOVA(model, *args):\n",
    "\n",
    "    X_train = args[0]\n",
    "    original_n_features = len(X_train.columns)\n",
    "\n",
    "    train_acc_dict = {}  # 0 is a dummy accuracy for k=0 features\n",
    "    test_acc_dict = {}\n",
    "    train_test_dataset = {}\n",
    "\n",
    "    for k in range(1, original_n_features + 1):\n",
    "        print(f\"k: {k}\")\n",
    "        train_test_dataset_after_ANOVA = get_df_with_top_k_features(k, *args)\n",
    "        train_accuracy, test_accuracy = model(*train_test_dataset_after_ANOVA)\n",
    "        train_test_dataset[k] = train_test_dataset_after_ANOVA\n",
    "        train_acc_dict[k] = train_accuracy\n",
    "        test_acc_dict[k] = test_accuracy\n",
    "\n",
    "    # Find k that gives the highest accuracy\n",
    "    best_train_k = max(train_acc_dict, key=train_acc_dict.get)\n",
    "    best_test_k = max(test_acc_dict, key=test_acc_dict.get)\n",
    "\n",
    "    print(f\"\\033[96mBest k for train_accuracy:\\033[00m {best_train_k}\")\n",
    "    print(f\"\\033[96mBest k for test_accuracy:\\033[00m {best_test_k}\")\n",
    "\n",
    "    plot_ANOVA_test_graph(train_acc_dict, test_acc_dict)\n",
    "\n",
    "    return train_test_dataset[best_test_k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving forward, we can use ANOVA test for feature selection to reduce the number of features in our dataset before building our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# We use the pre-processing function 'process1' to get the feature space where no feature pair has a correlation value higher than 0.7.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_graph \u001b[38;5;241m=\u001b[39m df_graph \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      3\u001b[0m X_heatmap, y_heatmap \u001b[38;5;241m=\u001b[39m process1(df_graph)\n\u001b[1;32m      4\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(X_heatmap\u001b[38;5;241m.\u001b[39mcorr(), annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoolwarm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# We use the pre-processing function 'process1' to get the feature space where no feature pair has a correlation value higher than 0.7.\n",
    "df_graph = df_graph = df.copy()\n",
    "X_heatmap, y_heatmap = process1(df_graph)\n",
    "sns.heatmap(X_heatmap.corr(), annot=False, cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Filter Method for Feature Selection\n",
    "\n",
    "Filter method is a feature selection method in the preprocessing step, and it is independent of the machine learning algorithm deployed afterwards. In our case, we implemented two filtering method, based on Information Gain (IG) and Correlation respectively.\n",
    "\n",
    "1. **Information Gain (IG)**: This method measures the reduction in entropy from transforming a dataset in some way. It is often used in training decision trees. Information Gain can be applied to feature selection by evaluating the mutual information between each feature and the target variable. Features that have higher mutual information with the target variable are considered more informative and are thus selected.\n",
    "\n",
    "2. **Correlation**: This is a statistical measure that describes the size and direction of a relationship between variables. In feature selection, we often look for features that have a high correlation with the target variable but are not highly correlated with each other, to avoid redundancy.\n",
    "\n",
    "For both functions, we sort the features based on their scores in descending order. Higher scores indicate more important features.\n",
    "\n",
    "For better judging the optimal number of feature, we define a function `plot_feature_performance` to evaluate the performance of a model (balaneced Random Forest as example) as we vary the number of top features used. Finally, it plots the performance metrics f1 and recall (explained in the next chapter) against the number of features. With the aid of the plot, we determine the point of diminishing return through elbow method, selecting the optimal number of features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def information_gain(X, y):\n",
    "    mi_scores = mutual_info_classif(X, y, discrete_features=\"auto\")\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "\n",
    "def correlation_selection(X, y):\n",
    "    if isinstance(y, pd.Series):\n",
    "        y = y.to_frame(name=\"Target\")\n",
    "    elif isinstance(y, pd.DataFrame):\n",
    "        y.columns = [\"Target\"]\n",
    "\n",
    "    df_combined = pd.concat([X, y], axis=1)\n",
    "    correlation_matrix = df_combined.corr()\n",
    "    correlation_w_target = correlation_matrix[\"Target\"].drop(\"Target\")\n",
    "    return correlation_w_target.abs().sort_values(ascending=False)\n",
    "\n",
    "\n",
    "def plot_feature_performance(X, y, score_series, model, max_features=None):\n",
    "    f1_results = []\n",
    "    recall_results = []\n",
    "    feature_counts = []\n",
    "\n",
    "    if not max_features:\n",
    "        max_features = len(score_series)\n",
    "\n",
    "    for i in range(1, max_features + 1):\n",
    "        top_features = score_series.nlargest(i).index\n",
    "        X_selected = X[top_features]\n",
    "\n",
    "        # Cross-validation F1 and recall scores\n",
    "        f1 = cross_val_score(model, X_selected, y, cv=5, scoring=\"f1\")\n",
    "        recall = cross_val_score(model, X_selected, y, cv=5, scoring=\"recall\")\n",
    "\n",
    "        f1_results.append(f1.mean())\n",
    "        recall_results.append(recall.mean())\n",
    "        feature_counts.append(i)\n",
    "\n",
    "    # Plotting the F1-score and recall results\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(\n",
    "        feature_counts,\n",
    "        f1_results,\n",
    "        marker=\"o\",\n",
    "        linestyle=\"-\",\n",
    "        markersize=8,\n",
    "        label=\"F1 Score\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        feature_counts,\n",
    "        recall_results,\n",
    "        marker=\"o\",\n",
    "        linestyle=\"-\",\n",
    "        markersize=8,\n",
    "        label=\"Recall\",\n",
    "    )\n",
    "    plt.xlabel(\"Number of Features\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(\"Model Performance vs. Number of Features\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Wrapper Method for Feature Selection\n",
    "\n",
    "The wrapper method for feature selection is a technique used to identify the most significant features for a predictive model. It works by starting with an empty set and adding features one by one, each time choosing the feature that, when added, most improves the model's F1 score - our desirable metric. This approach is iterative and selects features based on their contribution to the model's predictive accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def forward_feature_selection(model, X_train, y_train, X_test, y_test):\n",
    "    selected_features = []\n",
    "    best_f1 = 0\n",
    "    features = list(X_train.columns)\n",
    "\n",
    "    for _ in range(len(features)):\n",
    "        f1_scores = []\n",
    "        for feature in features:\n",
    "            if feature not in selected_features:\n",
    "                temp_features = selected_features + [feature]\n",
    "                model.fit(X_train[temp_features], y_train)\n",
    "                y_pred = model.predict(X_test[temp_features])\n",
    "                f1 = f1_score(y_test, y_pred)\n",
    "                f1_scores.append((feature, f1))\n",
    "\n",
    "        # Find the best feature and its f1 score\n",
    "        f1_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        best_feature, best_feature_f1 = f1_scores[0]\n",
    "\n",
    "        if best_feature_f1 > best_f1:\n",
    "            print(f\"Adding {best_feature} improved F1 to {best_feature_f1}\")\n",
    "            best_f1 = best_feature_f1\n",
    "            selected_features.append(best_feature)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    print(\"Selected features:\", selected_features)\n",
    "    return selected_features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
