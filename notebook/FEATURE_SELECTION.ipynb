{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [ANOVA test for Feature selection](#chapter1)\n",
    "2. [Filter Method for Feature Selection](#chapter2)\n",
    "3. [Wrapper Method for Feature Selection](#chapter3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the best set of features for out Machine learning models. Because irrelavant features can:\n",
    "- **Increase Model Complexity**: Because nnecessary features can lead to overfitting, where the model performs well on training data but poorly on unseen data.\n",
    "- **Reduce Model Interpretability**: A large number of features makes it difficult to understand how the model arrives at its predictions.\n",
    "- **Slow Down Training Time**: Training models with irrelevant features takes longer and consumes more computational resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from data_cleaning import get_Xy, med_impute, normalise, drop_high_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acess dataframe from EDA step\n",
    "df_to_share = pd.read_pickle(\"df_to_share.pkl\")\n",
    "df_to_share.head()\n",
    "df = df_to_share.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process0(df):\n",
    "    X, y = get_Xy(df)\n",
    "    X_imputed, y = med_impute(X, y)\n",
    "    X_scaled_df = normalise(X_imputed)\n",
    "    return X_scaled_df, y\n",
    "\n",
    "\n",
    "# function to pre-process the data\n",
    "def process1(df):\n",
    "    X, y = get_Xy(df)\n",
    "    X_imputed, y = med_impute(X, y)\n",
    "    X_scaled_df = normalise(X_imputed)\n",
    "    return drop_high_corr(X_scaled_df), y\n",
    "\n",
    "\n",
    "# function to obtain train and test sets\n",
    "def process2(df):\n",
    "    X, y = process1(df)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=3244\n",
    "    )\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# function to obtain train and test sets with sythesised instances of the minority class\n",
    "def pre_process(df):\n",
    "    X, y = process1(df)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=3244\n",
    "    )\n",
    "    smote = SMOTE(random_state=3244)\n",
    "    X_smote, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    return X_smote, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "#### my functions\n",
    "from data_cleaning import df_cleaning, df_preprocess_after_EDA\n",
    "\n",
    "\n",
    "def preprocess(df):\n",
    "    X, y = get_Xy(df)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=3244\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def preprocess_with_SMOTE(df):\n",
    "    X, y = get_Xy(df)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=3244\n",
    "    )\n",
    "    smote = SMOTE(random_state=3244)\n",
    "    X_smote, y_train = smote.fit_resample(X_train, y_train)\n",
    "    return X_smote, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Coefficient\n",
    "If two features are correlated, we can predict one feature from the other. Hence, we can drop one of the feauture, as the second one does not add additional information. \n",
    "Here, we set the correlation threshold for highly correlated features as 0.5. If two features are highly correlated, we can drop the feature with a lower correlation coefficient value to the target variable.  We can also check for multicollinearity for correlation between more than 2 features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the pre-processing function 'process1' to get the feature space where no feature pair has a correlation value higher than 0.7.\n",
    "df_graph = df_graph = df.copy()\n",
    "X_heatmap, y_heatmap = process1(df_graph)\n",
    "sns.heatmap(X_heatmap.corr(), annot=False, cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ANOVA test for feature selection\n",
    "**ANOVA (Analysis of Variance)** is a statistical test used in feature selection to identify features that have a significant influence on the target variable. \n",
    "\n",
    "Steps to select the best k features (where k is a chosen number):\n",
    "- Focuses on Variance: ANOVA analyses the variation in a feature's values. It compares the variation between groups (bankrupt vs. non-bankrupt) to the variation within each group.\n",
    "- Low p-value indicates Impact: Features with a low p-value (from the F-statistic) suggest a strong statistical difference in the feature's values between bankrupt and non-bankrupt companies. This implies the feature likely has a real impact on predicting bankruptcy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ANOVA_test_graph(train_acc_dict, test_acc_dict):\n",
    "    # Extract keys and values from train_acc_dict and test_acc_dict\n",
    "    train_k_values, train_accuracy_values = zip(*train_acc_dict.items())\n",
    "    test_k_values, test_accuracy_values = zip(*test_acc_dict.items())\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    # Plot train accuracy\n",
    "    plt.plot(\n",
    "        train_k_values, train_accuracy_values, label=\"Train Accuracy\", color=\"blue\"\n",
    "    )\n",
    "    # Plot test accuracy\n",
    "    plt.plot(test_k_values, test_accuracy_values, label=\"Test Accuracy\", color=\"green\")\n",
    "\n",
    "    # Find k values corresponding to maximum accuracies\n",
    "    best_train_k = max(train_acc_dict, key=train_acc_dict.get)\n",
    "    best_test_k = max(test_acc_dict, key=test_acc_dict.get)\n",
    "    best_train_accuracy = train_acc_dict[best_train_k]\n",
    "    best_test_accuracy = test_acc_dict[best_test_k]\n",
    "\n",
    "    # Annotate the point corresponding to the peak train accuracy\n",
    "    plt.annotate(\n",
    "        f\"Max Train Accuracy\\nk={best_train_k}, Acc={best_train_accuracy:.2f}\",\n",
    "        xy=(best_train_k, best_train_accuracy),\n",
    "        xytext=(-30, 20),\n",
    "        textcoords=\"offset points\",\n",
    "        arrowprops=dict(arrowstyle=\"->\", color=\"blue\"),\n",
    "    )\n",
    "\n",
    "    # Annotate the point corresponding to the peak test accuracy\n",
    "    plt.annotate(\n",
    "        f\"Max Test Accuracy\\nk={best_test_k}, Acc={best_test_accuracy:.2f}\",\n",
    "        xy=(best_test_k, best_test_accuracy),\n",
    "        xytext=(30, -30),\n",
    "        textcoords=\"offset points\",\n",
    "        arrowprops=dict(arrowstyle=\"->\", color=\"green\"),\n",
    "    )\n",
    "\n",
    "    # Label axes and add title\n",
    "    plt.xlabel(\"Number of Features (k)\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Accuracy vs. Number of Features from ANOVA test\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "## Note: *args follow the convention X_train, X_test, y_train, y_test\n",
    "def get_df_with_top_k_features(k_features, *args):  # after pre_process(df)\n",
    "    X_train = args[0]\n",
    "    X_test = args[1]\n",
    "    y_train = args[2]\n",
    "    y_test = args[3]\n",
    "\n",
    "    # define feature selection\n",
    "    fs = SelectKBest(score_func=f_classif, k=k_features)\n",
    "\n",
    "    # apply feature selection\n",
    "    fs.fit_transform(X_train, y_train)\n",
    "\n",
    "    # Take the features with the highest F-scores\n",
    "    fs_scores_array = np.array(fs.scores_)\n",
    "\n",
    "    # Get the indices that would sort the array in descending order\n",
    "    sorted_indices_desc = np.argsort(fs_scores_array)[::-1]\n",
    "\n",
    "    # Take the top k indices\n",
    "    top_indices = sorted_indices_desc[:k_features]\n",
    "\n",
    "    selected_columns_X_train = X_train.iloc[:, top_indices]\n",
    "    selected_columns_X_test = X_test.iloc[:, top_indices]\n",
    "\n",
    "    return selected_columns_X_train, selected_columns_X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def find_best_k_features_from_ANOVA(model, *args):\n",
    "\n",
    "    X_train = args[0]\n",
    "    original_n_features = len(X_train.columns)\n",
    "\n",
    "    train_acc_dict = {}  # 0 is a dummy accuracy for k=0 features\n",
    "    test_acc_dict = {}\n",
    "    train_test_dataset = {}\n",
    "\n",
    "    for k in range(1, original_n_features + 1):\n",
    "        print(f\"k: {k}\")\n",
    "        train_test_dataset_after_ANOVA = get_df_with_top_k_features(k, *args)\n",
    "        train_accuracy, test_accuracy = model(*train_test_dataset_after_ANOVA)\n",
    "        train_test_dataset[k] = train_test_dataset_after_ANOVA\n",
    "        train_acc_dict[k] = train_accuracy\n",
    "        test_acc_dict[k] = test_accuracy\n",
    "\n",
    "    # Find k that gives the highest accuracy\n",
    "    best_train_k = max(train_acc_dict, key=train_acc_dict.get)\n",
    "    best_test_k = max(test_acc_dict, key=test_acc_dict.get)\n",
    "\n",
    "    print(f\"\\033[96mBest k for train_accuracy:\\033[00m {best_train_k}\")\n",
    "    print(f\"\\033[96mBest k for test_accuracy:\\033[00m {best_test_k}\")\n",
    "\n",
    "    plot_ANOVA_test_graph(train_acc_dict, test_acc_dict)\n",
    "\n",
    "    return train_test_dataset[best_test_k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using ANOVA test on our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Example of using the function\u001b[39;00m\n\u001b[1;32m      7\u001b[0m svm_model \u001b[38;5;241m=\u001b[39m SVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m best_k \u001b[38;5;241m=\u001b[39m find_best_k_features_from_ANOVA(svm_model, train_test_dataset)\n\u001b[1;32m      9\u001b[0m best_k\n",
      "Cell \u001b[0;32mIn[20], line 78\u001b[0m, in \u001b[0;36mfind_best_k_features_from_ANOVA\u001b[0;34m(model, *args)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_best_k_features_from_ANOVA\u001b[39m(model, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     77\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 78\u001b[0m     original_n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m     80\u001b[0m     train_acc_dict \u001b[38;5;241m=\u001b[39m {}  \u001b[38;5;66;03m# 0 is a dummy accuracy for k=0 features\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     test_acc_dict \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "train_test_dataset = preprocess(df)\n",
    "train_test_smote_dataset = preprocess_with_SMOTE(df)\n",
    "\n",
    "# Example of using the function\n",
    "svm_model = SVC(kernel=\"sigmoid\")\n",
    "best_k = find_best_k_features_from_ANOVA(svm_model, train_test_dataset)\n",
    "best_k_smote = find_best_k_features_from_ANOVA(svm_model, train_test_smote_dataset)\n",
    "best_k\n",
    "best_k_smote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Filter Method for Feature Selection\n",
    "\n",
    "Filter method is a feature selection method in the preprocessing step, and it is independent of the machine learning algorithm deployed afterwards. In our case, we implemented two filtering method, based on Information Gain (IG) and Correlation respectively.\n",
    "\n",
    "1. **Information Gain (IG)**: This method measures the reduction in entropy from transforming a dataset in some way. It is often used in training decision trees. Information Gain can be applied to feature selection by evaluating the mutual information between each feature and the target variable. Features that have higher mutual information with the target variable are considered more informative and are thus selected.\n",
    "\n",
    "2. **Correlation**: This is a statistical measure that describes the size and direction of a relationship between variables. In feature selection, we often look for features that have a high correlation with the target variable but are not highly correlated with each other, to avoid redundancy.\n",
    "\n",
    "For both functions, we sort the features based on their scores in descending order. Higher scores indicate more important features.\n",
    "\n",
    "For better judging the optimal number of feature, we define a function `plot_feature_performance` to evaluate the performance of a model (balaneced Random Forest as example) as we vary the number of top features used. Finally, it plots the performance metrics f1 and recall (explained in the next chapter) against the number of features. With the aid of the plot, we determine the point of diminishing return through elbow method, selecting the optimal number of features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def information_gain(X, y):\n",
    "    mi_scores = mutual_info_classif(X, y, discrete_features=\"auto\")\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "\n",
    "def correlation_selection(X, y):\n",
    "    if isinstance(y, pd.Series):\n",
    "        y = y.to_frame(name=\"Target\")\n",
    "    elif isinstance(y, pd.DataFrame):\n",
    "        y.columns = [\"Target\"]\n",
    "\n",
    "    df_combined = pd.concat([X, y], axis=1)\n",
    "    correlation_matrix = df_combined.corr()\n",
    "    correlation_w_target = correlation_matrix[\"Target\"].drop(\"Target\")\n",
    "    return correlation_w_target.abs().sort_values(ascending=False)\n",
    "\n",
    "\n",
    "def plot_feature_performance(X, y, score_series, model, max_features=None):\n",
    "    f1_results = []\n",
    "    recall_results = []\n",
    "    feature_counts = []\n",
    "\n",
    "    if not max_features:\n",
    "        max_features = len(score_series)\n",
    "\n",
    "    for i in range(1, max_features + 1):\n",
    "        top_features = score_series.nlargest(i).index\n",
    "        X_selected = X[top_features]\n",
    "\n",
    "        # Cross-validation F1 and recall scores\n",
    "        f1 = cross_val_score(model, X_selected, y, cv=5, scoring=\"f1\")\n",
    "        recall = cross_val_score(model, X_selected, y, cv=5, scoring=\"recall\")\n",
    "\n",
    "        f1_results.append(f1.mean())\n",
    "        recall_results.append(recall.mean())\n",
    "        feature_counts.append(i)\n",
    "\n",
    "    # Plotting the F1-score and recall results\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(\n",
    "        feature_counts,\n",
    "        f1_results,\n",
    "        marker=\"o\",\n",
    "        linestyle=\"-\",\n",
    "        markersize=8,\n",
    "        label=\"F1 Score\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        feature_counts,\n",
    "        recall_results,\n",
    "        marker=\"o\",\n",
    "        linestyle=\"-\",\n",
    "        markersize=8,\n",
    "        label=\"Recall\",\n",
    "    )\n",
    "    plt.xlabel(\"Number of Features\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(\"Model Performance vs. Number of Features\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of using the function\n",
    "train_test_dataset = preprocess(df)\n",
    "train_test_smote_dataset = preprocess_with_SMOTE(df)\n",
    "\n",
    "svm_model = SVC(kernel=\"sigmoid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Wrapper Method for Feature Selection\n",
    "Wrappers require some method to search the space of all possible subsets of features, assessing their quality by learning and evaluating a classifier with that feature subset. The feature selection process is based on a specific machine learning algorithm we are trying to fit on a given dataset. It follows a greedy search approach by evaluating all the possible combinations of features against the evaluation criterion. The wrapper methods usually result in better predictive accuracy than filter methods.\n",
    "\n",
    "Wrapper methods:\n",
    "1. Forward Feature Selection\n",
    "2. Backward Feature Elimination\n",
    "3. Exhaustive Feature Selection\n",
    "4. Recursive Feature Elimination\n",
    "\n",
    "The wrapper method for feature selection is a technique used to identify the most significant features for a predictive model. It works by starting with an empty set and adding features one by one, each time choosing the feature that, when added, most improves the model's F1 score - our desirable metric. This approach is iterative and selects features based on their contribution to the model's predictive accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def forward_feature_selection(model, X_train, y_train, X_test, y_test):\n",
    "    selected_features = []\n",
    "    best_f1 = 0\n",
    "    features = list(X_train.columns)\n",
    "\n",
    "    for _ in range(len(features)):\n",
    "        f1_scores = []\n",
    "        for feature in features:\n",
    "            if feature not in selected_features:\n",
    "                temp_features = selected_features + [feature]\n",
    "                model.fit(X_train[temp_features], y_train)\n",
    "                y_pred = model.predict(X_test[temp_features])\n",
    "                f1 = f1_score(y_test, y_pred)\n",
    "                f1_scores.append((feature, f1))\n",
    "\n",
    "        # Find the best feature and its f1 score\n",
    "        f1_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        best_feature, best_feature_f1 = f1_scores[0]\n",
    "\n",
    "        if best_feature_f1 > best_f1:\n",
    "            print(f\"Adding {best_feature} improved F1 to {best_feature_f1}\")\n",
    "            best_f1 = best_feature_f1\n",
    "            selected_features.append(best_feature)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    print(\"Selected features:\", selected_features)\n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of using the function\n",
    "train_test_dataset = preprocess(df)\n",
    "train_test_smote_dataset = preprocess_with_SMOTE(df)\n",
    "\n",
    "svm_model = SVC(kernel=\"sigmoid\")\n",
    "forward_feature_selection(svm_model, train_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedded Methods\n",
    "These methods encompass the benefits of both the wrapper and filter methods by including interactions of features but also maintaining reasonable computational costs. Embedded methods are iterative in the sense that takes care of each iteration of the model training process and carefully extract those features which contribute the most to the training for a particular iteration.\n",
    "\n",
    "Example techniques:\n",
    "1. LASSO Regularisation (L1)\n",
    "2. Random Forest Importance\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
